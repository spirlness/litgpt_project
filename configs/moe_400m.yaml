bias: false
block_size: 2048
mlp_class_name: LLaMAMoE
moe_intermediate_size: 4096
n_embd: 1024
n_expert: 16
n_expert_per_token: 4
moe_aux_loss_weight: 0.01
moe_router_stats: true
n_head: 16
n_layer: 24
n_query_groups: 4
name: MoE-400M
norm_class_name: RMSNorm
norm_eps: 1e-5
padded_vocab_size: 50257
parallel_residual: false
rope_base: 10000
vocab_size: 50257

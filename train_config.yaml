out_dir: ./checkpoints
precision: bf16-mixed
tokenizer_dir: ./data/tokenizer

data:
  class_path: litgpt.data.TextFiles
  init_args:
    train_data_path: ./data/custom_text/train
    val_data_path: ./data/custom_text/val
    num_workers: 2

train:
  global_batch_size: 8
  log_interval: 1
  max_tokens: 320000
  lr_warmup_steps: 5
  micro_batch_size: 1
  save_interval: 10

logger_name: csv

optimizer:
  class_path: torch.optim.AdamW
  init_args:
    lr: 0.0003
    weight_decay: 0.01

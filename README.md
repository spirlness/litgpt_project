# LitGPT MoE è®­ç»ƒé¡¹ç›®

æœ¬é¡¹ç›®åŸºäº [LitGPT](https://github.com/Lightning-AI/litgpt) æ¡†æ¶ï¼Œä¸“æ³¨äºåœ¨ TinyStories æ•°æ®é›†ä¸Šè®­ç»ƒæ··åˆä¸“å®¶ (MoE) è¯­è¨€æ¨¡å‹ã€‚é¡¹ç›®ç»è¿‡ä¼˜åŒ–ï¼Œæ”¯æŒä»æœ¬åœ°æ¶ˆè´¹çº§æ˜¾å¡ (å¦‚ RTX 3060) åˆ°äº‘ç«¯å¤šå¡ç¯å¢ƒçš„è®­ç»ƒã€‚

## âœ¨ ç‰¹æ€§

- **æ··åˆä¸“å®¶ (MoE)**: æ”¯æŒé…ç½®ä¸“å®¶æ•°é‡ã€æ¿€æ´»ä¸“å®¶æ•°ç­‰ MoE å…³é”®å‚æ•°ã€‚
- **ç¯å¢ƒé€‚é…**: æä¾›é’ˆå¯¹å•å¡ (RTX 3060 6GB) å’Œå¤šå¡ (Kaggle T4 x2) çš„ä¸“ç”¨é…ç½®ã€‚
- **æ•°æ®ç®¡çº¿**: åŒ…å«ä»ä¸‹è½½ã€æ¸…æ´—åˆ° Tokenize çš„å®Œæ•´æ•°æ®å¤„ç†è„šæœ¬ã€‚
- **ç›‘æ§é›†æˆ**: æ”¯æŒ Weights & Biases (W&B) è¿›è¡Œå®éªŒç›‘æ§å’Œæ•°æ®é›†ç‰ˆæœ¬ç®¡ç†ã€‚
- **æœ¬åœ°ä¼˜åŒ–**: é’ˆå¯¹ Windows å’Œæœ‰é™æ˜¾å­˜ç¯å¢ƒè¿›è¡Œäº†ä¸“é—¨é€‚é…ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå®‰è£…

æœ¬é¡¹ç›®ä½¿ç”¨ `uv` è¿›è¡Œä¾èµ–ç®¡ç†ï¼ˆæ¨èï¼‰ï¼Œä¹Ÿæ”¯æŒæ ‡å‡† pipã€‚

```bash
# å®‰è£… uv (å¦‚æœå°šæœªå®‰è£…)
pip install uv

# åŒæ­¥ä¾èµ– (ä¼šè‡ªåŠ¨åˆ›å»º .venv è™šæ‹Ÿç¯å¢ƒ)
uv sync

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ (Windows Git Bash)
source .venv/Scripts/activate
# æˆ–è€… Windows CMD
# .venv\Scripts\activate.bat
```

### 2. æ•°æ®å‡†å¤‡

```bash
# ä¸‹è½½ TinyStories æ•°æ®é›†
python scripts/download_tinystories.py

# é¢„å¤„ç†ä¸ Tokenize (ç”Ÿæˆ index.json ç´¢å¼•)
python prepare_data.py --data-dir data/custom_text
```

### 3. å¼€å§‹è®­ç»ƒ

#### ğŸ’» æœ¬åœ°å•å¡è®­ç»ƒ (æ¨è RTX 3060/4060 ç­‰)

ä½¿ç”¨æˆ‘ä»¬ä¸“é—¨ä¼˜åŒ–çš„é…ç½®æ–‡ä»¶ `configs/optimized_rtx3060.yaml`ï¼Œè¯¥é…ç½®é’ˆå¯¹ 6GB+ æ˜¾å­˜è¿›è¡Œäº†ä¼˜åŒ–ï¼ˆå•å¡ã€ä½ Batch Sizeã€æ¢¯åº¦ç´¯ç§¯ï¼‰ã€‚

```bash
# è®­ç»ƒå®Œæ•´æ¨¡å‹ (200M å‚æ•°)
python run_train.py --model-config configs/moe_200m.yaml --train-config configs/optimized_rtx3060.yaml

# å¿«é€Ÿè°ƒè¯• (30M å‚æ•°ï¼Œå¯åŠ¨æ›´å¿«)
python run_train.py --model-config configs/moe_30m_debug.yaml --train-config configs/optimized_rtx3060.yaml
```

#### â˜ï¸ äº‘ç«¯/å¤šå¡è®­ç»ƒ

```bash
# ä½¿ç”¨ Kaggle T4 x2 é…ç½®
python run_train.py --train-config configs/kaggle_t4_ddp.yaml
```

### 4. æ¨¡å‹ç”Ÿæˆä¸è¯„ä¼°

```bash
# æ–‡æœ¬ç”Ÿæˆæµ‹è¯•
python generate.py --prompt "Once upon a time" --checkpoint_dir checkpoints/final

# è¯„ä¼°æ¨¡å‹
python evaluate.py --checkpoint_dir checkpoints/final
```

## ğŸ“‚ é¡¹ç›®ç»“æ„

```text
litgpt_project/
â”œâ”€â”€ configs/                 # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ optimized_rtx3060.yaml # [æ–°å¢] æœ¬åœ°å•å¡ä¼˜åŒ–é…ç½®
â”‚   â”œâ”€â”€ kaggle_t4_ddp.yaml   # Kaggle åŒå¡ DDP é…ç½®
â”‚   â”œâ”€â”€ moe_30m_debug.yaml   # è°ƒè¯•ç”¨å°æ¨¡å‹é…ç½®
â”‚   â””â”€â”€ moe_200m.yaml        # é»˜è®¤ 200M æ¨¡å‹é…ç½®
â”œâ”€â”€ data/                    # æ•°æ®ç›®å½• (è‡ªåŠ¨ç”Ÿæˆ)
â”œâ”€â”€ docs/                    # æ–‡æ¡£ä¸æŠ¥å‘Š
â”‚   â””â”€â”€ reports/             # å†å²ä¿®å¤æŠ¥å‘Šä¸æŠ€æœ¯æ–‡æ¡£
â”œâ”€â”€ scripts/                 # è¾…åŠ©è„šæœ¬
â”‚   â”œâ”€â”€ download_tinystories.py # æ•°æ®é›†ä¸‹è½½
â”‚   â”œâ”€â”€ generate_index_json.py  # ç´¢å¼•ç”Ÿæˆå·¥å…·
â”‚   â”œâ”€â”€ test_compile.py         # ç¼–è¯‘æµ‹è¯•
â”‚   â”œâ”€â”€ env_sanity_check.py     # ç¯å¢ƒæ£€æŸ¥
â”‚   â””â”€â”€ verify_flash.py         # Flash Attention éªŒè¯
â”œâ”€â”€ src/                     # æºä»£ç æ¨¡å—
â”‚   â””â”€â”€ litgpt_moe/          # [æ–°å¢] æ ¸å¿ƒåŒ…
â”‚       â”œâ”€â”€ fixed_text_files.py     # ä¿®å¤ç‰ˆæ•°æ®åŠ è½½å™¨
â”‚       â”œâ”€â”€ wandb_dataset.py        # W&B æ•°æ®é›†é›†æˆ
â”‚       â”œâ”€â”€ config.py               # MoE é…ç½®ç±»
â”‚       â””â”€â”€ utils.py                # é€šç”¨å·¥å…·
â”œâ”€â”€ prepare_data.py          # æ•°æ®é¢„å¤„ç†å…¥å£
â”œâ”€â”€ run_train.py             # è®­ç»ƒä¸»ç¨‹åº
â”œâ”€â”€ generate.py              # ç”Ÿæˆè„šæœ¬
â”œâ”€â”€ evaluate.py              # è¯„ä¼°è„šæœ¬
â””â”€â”€ pyproject.toml           # é¡¹ç›®ä¾èµ–å®šä¹‰
```

## âš™ï¸ é…ç½®è¯´æ˜

### è®­ç»ƒé…ç½® (`configs/*.yaml`)

| å‚æ•° | è¯´æ˜ | æ¨èå€¼ (æœ¬åœ°) |
|------|------|---------------|
| `devices` | ä½¿ç”¨ GPU æ•°é‡ | `1` |
| `micro_batch_size` | å•æ¬¡å‰å‘ä¼ æ’­çš„æ ·æœ¬æ•° (æ˜¾å­˜æ•æ„Ÿ) | `2` æˆ– `4` |
| `global_batch_size` | æ¢¯åº¦ç´¯ç§¯åçš„æ€» Batch Size | `64` æˆ– `128` |
| `gradient_checkpointing` | æ¢¯åº¦æ£€æŸ¥ç‚¹ (èŠ‚çœæ˜¾å­˜) | `true` |
| `num_workers` | æ•°æ®åŠ è½½è¿›ç¨‹æ•° | Windowsè®¾ä¸º `0` |

### æ¨¡å‹æ¶æ„

é»˜è®¤æ¨¡å‹é…ç½® (`configs/moe_200m.yaml`)ï¼š
- **æ€»å‚æ•°é‡**: ~200M
- **ä¸“å®¶æ•°**: 8 (Top-2 æ¿€æ´»)
- **å±‚æ•°**: 12
- **éšè—å±‚ç»´åº¦**: 768

## ğŸ› ï¸ å¸¸è§é—®é¢˜ä¸ä¿®å¤

1. **Windows ä¸‹æŠ¥é”™ `BrokenPipeError` æˆ– DataLoader å¡ä½**
   - **è§£å†³**: ç¡®ä¿åœ¨é…ç½®ä¸­è®¾ç½® `num_workers: 0`ã€‚`local_rtx3060.yaml` å·²é»˜è®¤åŒ…å«æ­¤è®¾ç½®ã€‚

2. **OOM (Out of Memory)**
   - **è§£å†³**: å‡å° `micro_batch_size` (å¦‚è®¾ä¸º 1)ï¼Œæˆ–è€…ä½¿ç”¨æ›´å°çš„æ¨¡å‹é…ç½® (`moe_30m_debug.yaml`)ã€‚

3. **`AttributeError: 'Config' object has no attribute 'moe_...'`**
   - **è§£å†³**: è¯·ç¡®ä¿ä½¿ç”¨æœ€æ–°çš„ `run_train.py`ï¼Œæˆ‘ä»¬å·²ä¿®å¤äº† MoE å‚æ•°æ³¨å…¥çš„é€»è¾‘ã€‚

4. **æ¢å¤è®­ç»ƒå¤±è´¥ (Size Mismatch)**
   - **è§£å†³**: ç¡®ä¿ `resume` å‚æ•°è®¾ç½®ä¸º `null` (åœ¨é…ç½®æ–‡ä»¶ä¸­) ä»¥é‡æ–°å¼€å§‹è®­ç»ƒï¼Œæˆ–è€…æŒ‡å®šæ­£ç¡®çš„ checkpoint è·¯å¾„ã€‚ä¸åŒæ¨¡å‹é…ç½®äº§ç”Ÿçš„ checkpoint ä¸å…¼å®¹ã€‚

## ğŸ“Š ç›‘æ§

æ”¯æŒ Weights & Biases ç›‘æ§ã€‚è®¾ç½®ç¯å¢ƒå˜é‡æˆ–åœ¨ `prepare_data.py` ä¸­å¯ç”¨ï¼š

```bash
export WANDB_PROJECT="litgpt-moe"
python prepare_data.py --log-to-wandb
```
